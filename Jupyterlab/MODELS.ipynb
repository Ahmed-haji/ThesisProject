{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8851cacf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Time Series Forecasting with XGBoost / GBRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d2ea7a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from random import gauss\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "sys.path.insert(2,'..')\n",
    "import functions\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "import annualized_rv as arv\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor # Random Forest model\n",
    "from sklearn.ensemble import GradientBoostingRegressor # Gradient Boosting model\n",
    "from sklearn.ensemble import AdaBoostRegressor # AdaBoost model\n",
    "import sklearn.ensemble as ensemble\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import DataProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0951eacd-7082-4a67-a683-74134f8b8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the historic implied vol data calculated in the dailyaverageIV notebook\n",
    "\n",
    "aaplHistIV = pd.read_pickle('historicImpliedVolData/aapl_mean_iv_2017_2022.pkl')\n",
    "googHistIV = pd.read_pickle('historicImpliedVolData/goog_mean_iv_2017_2022.pkl')\n",
    "msftHistIV = pd.read_pickle('historicImpliedVolData/msft_mean_iv_2017_2022.pkl')\n",
    "ndxHistIV = pd.read_pickle('historicImpliedVolData/ndx_mean_iv_2017_2022.pkl')\n",
    "spyHistIV = pd.read_pickle('historicImpliedVolData/spc_mean_iv_2017_2022.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5a97a6-0964-4061-98b7-37cd3726f4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['SPY']: ConnectionError(MaxRetryError('HTTPSConnectionPool(host=\\'fc.yahoo.com\\', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000029B40A5E310>: Failed to resolve \\'fc.yahoo.com\\' ([Errno 11001] getaddrinfo failed)\"))'))\n",
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = DataProcess.preprocess_data(spyHistIV, 'SPY', seq_length=60, splits=5, window=21) #preprocess spy \n",
    "X_train_reshape = X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
    "X_test_reshape = X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
    "#reshape data for xgboost\n",
    "def reshape2d(X_train,X_test):\n",
    "    X_train = X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
    "    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2988619-a149-4bf7-a799-f8e871a14107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelandeval(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    MSE,RMSE, MAE, R2 = DataProcess.evaluate_regression_metrics(y_test, y_pred)\n",
    "    \n",
    "    return RMSE, MAE, R2, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b8fe6da-3a57-4885-be1a-3966593abdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21991062797022953,\n",
       " 0.17311773731482058,\n",
       " 0.47953121360780104,\n",
       " 0.0483606842942607)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost model\n",
    "\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror',n_estimators=1000)\n",
    "modelandeval(model,X_train_reshape, X_test_reshape, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a00052dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20167229059689526,\n",
       " 0.15555989431008957,\n",
       " 0.5622816900213097,\n",
       " 0.040671712794598566)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomForestModel\n",
    "model = ensemble.RandomForestRegressor(n_estimators=100) # reccomended forest tree size\n",
    "modelandeval(model,X_train_reshape, X_test_reshape, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48c1c830",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20045185612310418,\n",
       " 0.15307376879904414,\n",
       " 0.5675634282216453,\n",
       " 0.04018094662319766)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GBRT Model\n",
    "model =ensemble.GradientBoostingRegressor()\n",
    "modelandeval(model,X_train_reshape, X_test_reshape, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a554ada6-f337-47b6-ba9f-e99f3ae476a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2662655971289159,\n",
       " 0.21761078110714738,\n",
       " 0.23698624758007736,\n",
       " 0.07089736821441814)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaBoost Model\n",
    "model = ensemble.AdaBoostRegressor()\n",
    "modelandeval(model,X_train_reshape, X_test_reshape, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27681917-fce8-447d-9afd-d4893545eb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23724663377076785,\n",
       " 0.1839884397165235,\n",
       " 0.3942375207345338,\n",
       " 0.05628596523556084)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STACKING MODEL \n",
    "\n",
    "estimators = [\n",
    "    ('rf', ensemble.RandomForestRegressor(n_estimators=100)),\n",
    "    ('gbrt', ensemble.GradientBoostingRegressor()),\n",
    "    ('xgb', xgb.XGBRegressor(objective ='reg:squarederror',n_estimators=1000))\n",
    "]\n",
    "\n",
    "model = ensemble.StackingRegressor(estimators=estimators, final_estimator=ensemble.RandomForestRegressor(n_estimators=100))\n",
    "modelandeval(model,X_train_reshape, X_test_reshape, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074d16bf-d038-4a46-add5-b880aa8862b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# pass tensors instead of numpy arrays\u001b[39;00m\n\u001b[0;32m     13\u001b[0m X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32), [X_train, y_train, X_test, y_test])\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_tensor)\n\u001b[0;32m     16\u001b[0m y_test_tensor \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_test_tensor)  \u001b[38;5;66;03m# Ensure y_test is a numpy array for consistency\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    915\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[0;32m    916\u001b[0m           bound_args\n\u001b[0;32m    917\u001b[0m       )\n\u001b[0;32m    918\u001b[0m   )\n\u001b[1;32m--> 919\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    920\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[0;32m    925\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#LSTM Model\n",
    "seq_length = 100\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(seq_length, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    keras.layers.LSTM(seq_length),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# pass tensors instead of numpy arrays\n",
    "X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = map(lambda x: tf.convert_to_tensor(x, dtype=tf.float32), [X_train, y_train, X_test, y_test])\n",
    "model.fit(X_train_tensor, y_train_tensor, epochs=50, batch_size=32)\n",
    "y_pred = model.predict(X_test_tensor)\n",
    "y_test_tensor = np.array(y_test_tensor)  # Ensure y_test is a numpy array for consistency\n",
    "\n",
    "DataProcess.evaluate_regression_metrics(y_test_tensor, y_pred)\n",
    "DataProcess.plot(y_test_tensor, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d7539b-4f04-4fd4-877a-cef86f6538e3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d1dc9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Using other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2061a5-65ae-4d35-867c-363e7d4ea07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_for_tickers(ticker_data_dict, seq_length, splits=5, window=21,reshape = True):\n",
    "    X_train_reshape_list = []\n",
    "    X_test_reshape_list = []\n",
    "    y_train_reshape_list = []\n",
    "    y_test_reshape_list = []\n",
    "    \n",
    "    for ticker, data in ticker_data_dict.items():\n",
    "        X_train, X_test, y_train, y_test = DataProcess.preprocess_data(data, ticker, seq_length=seq_length, splits=splits, window=window)\n",
    "        if reshape:\n",
    "            X_train, X_test = reshape2d(X_train,X_test)\n",
    "        X_train_reshape_list.append(X_train)\n",
    "        X_test_reshape_list.append(X_test)\n",
    "        y_train_reshape_list.append(y_train)\n",
    "        y_test_reshape_list.append(y_test)\n",
    "    return X_train_reshape_list, X_test_reshape_list, y_train_reshape_list, y_test_reshape_list, X_train.shape\n",
    "# Example usage\n",
    "ticker_data_dict = {\n",
    "    'AAPL': aaplHistIV,\n",
    "    'GOOG': googHistIV,\n",
    "    'MSFT': msftHistIV,\n",
    "    'SPY': spyHistIV\n",
    "}\n",
    "\n",
    "X_train_reshape_list, X_test_reshape_list, y_train_reshape_list, y_test_reshape_list,_ = preprocess_data_for_tickers(ticker_data_dict, seq_length=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c030b0c-2df5-4680-8197-047e6522f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_metrics(model,X_train, X_test, y_train, y_test):\n",
    "    RMSE, MAE, R2,MSE = 0,0,0,0\n",
    "    for X_train, X_test, y_train, y_test in zip(X_train, X_test, y_train, y_test):\n",
    "        RMSE_, MAE_, R2_, MSE_ = modelandeval(model,X_train, X_test, y_train, y_test)\n",
    "        RMSE += RMSE_\n",
    "        MAE += MAE_\n",
    "        R2 += R2_\n",
    "        MSE += MSE_\n",
    "    print(f'Average RMSE: {RMSE/4}')\n",
    "    print(f'Average MAE: {MAE/4}')\n",
    "    print(f'Average R2: {R2/4}')\n",
    "    print(f'Average MSE: {MSE/4}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73b33183",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.2854948037620782\n",
      "Average MAE: 0.21926092939376757\n",
      "Average R2: 0.5602175248375658\n",
      "Average MSE: 0.08338524382516437\n"
     ]
    }
   ],
   "source": [
    "# xgboost model\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror',n_estimators=1000)\n",
    "average_metrics(model,X_train_reshape_list, X_test_reshape_list, y_train_reshape_list, y_test_reshape_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb144d25-390f-4ce4-ae9e-f9f69af5892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.25718795413116174\n",
      "Average MAE: 0.19595120813050523\n",
      "Average R2: 0.6358340741543936\n",
      "Average MSE: 0.06770358975296158\n"
     ]
    }
   ],
   "source": [
    "#RandomForestModel\n",
    "model = ensemble.RandomForestRegressor(n_estimators=100) # reccomended forest tree size\n",
    "average_metrics(model,X_train_reshape_list, X_test_reshape_list, y_train_reshape_list, y_test_reshape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7785b43",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.2637671301021554\n",
      "Average MAE: 0.20111553873935972\n",
      "Average R2: 0.6270559078578957\n",
      "Average MSE: 0.07145403110851378\n"
     ]
    }
   ],
   "source": [
    "#GBRT Model\n",
    "\n",
    "model =ensemble.GradientBoostingRegressor()\n",
    "average_metrics(model,X_train_reshape_list, X_test_reshape_list, y_train_reshape_list, y_test_reshape_list)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0e7d036",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.26724811568527584\n",
      "Average MAE: 0.20615390616488843\n",
      "Average R2: 0.606708811396895\n",
      "Average MSE: 0.07282754831941747\n"
     ]
    }
   ],
   "source": [
    "#Bagging Model\n",
    "model = ensemble.BaggingRegressor()\n",
    "average_metrics(model,X_train_reshape_list, X_test_reshape_list, y_train_reshape_list, y_test_reshape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a940f465",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.2824828920859422\n",
      "Average MAE: 0.21781168132087775\n",
      "Average R2: 0.555702393373473\n",
      "Average MSE: 0.08102841279469328\n"
     ]
    }
   ],
   "source": [
    "#STACKING MODEL\n",
    "\n",
    "estimators = [\n",
    "    ('rf', ensemble.RandomForestRegressor(n_estimators=100)),\n",
    "    ('gbrt', ensemble.HistGradientBoostingRegressor()),\n",
    "    ('bag',ensemble.BaggingRegressor()),\n",
    "    ('xgb', xgb.XGBRegressor(objective ='reg:squarederror',n_estimators=1000))\n",
    "]\n",
    "\n",
    "model = ensemble.StackingRegressor(estimators=estimators, final_estimator=ensemble.RandomForestRegressor(n_estimators=100))\n",
    "average_metrics(model,X_train_reshape_list, X_test_reshape_list, y_train_reshape_list, y_test_reshape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff384ce3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#LSTM Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m----> 5\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m4\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[43mX_train_lstm\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train_lstm[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])),\n\u001b[0;32m      6\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m      7\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m ])\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_lstm' is not defined"
     ]
    }
   ],
   "source": [
    "#LSTM Model\n",
    "seq_length = 60\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(4, return_sequences=True, input_shape=(X_train_lstm[0].shape[1], X_train_lstm[0].shape[2])),\n",
    "    keras.layers.LSTM(4),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa168cc-ca77-4a9c-9806-9ac49dacde16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m rmse, mae, r2, mse  \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_train, X_test, y_train, y_test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mX_train_lstm\u001b[49m, X_test_lstm, y_train_lstm, y_test_lstm):\n\u001b[0;32m      4\u001b[0m     X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32), [X_train, y_train, X_test, y_test])\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train_tensor, y_train_tensor, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_lstm' is not defined"
     ]
    }
   ],
   "source": [
    "rmse, mae, r2, mse  = 0,0,0,0\n",
    "\n",
    "for X_train, X_test, y_train, y_test in zip(X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm):\n",
    "    X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = map(lambda x: tf.convert_to_tensor(x, dtype=tf.float32), [X_train, y_train, X_test, y_test])\n",
    "    model.fit(X_train_tensor, y_train_tensor, epochs=50, batch_size=32)\n",
    "    y_pred = model.predict(X_test_tensor)\n",
    "    y_test_tensor = np.array(y_test_tensor)  # Ensure y_test is a numpy array for consistency\n",
    "    MSE, RMSE, MAE, R2 = DataProcess.evaluate_regression_metrics(y_test_tensor, y_pred)\n",
    "    rmse += RMSE\n",
    "    mae += MAE\n",
    "    r2 += R2\n",
    "    mse += MSE\n",
    "\n",
    "print(f'Average RMSE: {rmse/4}')\n",
    "print(f'Average MAE: {mae/4}')\n",
    "print(f'Average R2: {r2/4}')\n",
    "print(f'Average MSE: {mse/4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d6e64ca-d226-45d0-8a6d-7833594e2561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#gru model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(4, return_sequences=True, input_shape=(X_train_lstm[0].shape[1], X_train_lstm[0].shape[2])),\n",
    "    keras.layers.GRU(4),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4b519a-3e60-4db2-ae61-3841d5dd1f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 1.2363\n",
      "Epoch 2/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.7625\n",
      "Epoch 3/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.5099\n",
      "Epoch 4/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.3957\n",
      "Epoch 5/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.3170\n",
      "Epoch 6/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.2767\n",
      "Epoch 7/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.2601\n",
      "Epoch 8/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.2559\n",
      "Epoch 9/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.2557\n",
      "Epoch 10/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1981\n",
      "Epoch 11/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1587\n",
      "Epoch 12/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.2182\n",
      "Epoch 13/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.2005\n",
      "Epoch 14/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1675\n",
      "Epoch 15/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1564\n",
      "Epoch 16/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1566\n",
      "Epoch 17/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1824\n",
      "Epoch 18/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1301\n",
      "Epoch 19/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1282\n",
      "Epoch 20/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1769\n",
      "Epoch 21/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1609\n",
      "Epoch 22/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1296\n",
      "Epoch 23/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1470\n",
      "Epoch 24/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1295\n",
      "Epoch 25/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1059\n",
      "Epoch 26/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1318\n",
      "Epoch 27/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1183\n",
      "Epoch 28/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1490\n",
      "Epoch 29/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1137\n",
      "Epoch 30/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1195\n",
      "Epoch 31/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1191\n",
      "Epoch 32/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1650\n",
      "Epoch 33/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1238\n",
      "Epoch 34/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1082\n",
      "Epoch 35/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1172\n",
      "Epoch 36/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1169\n",
      "Epoch 37/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1032\n",
      "Epoch 38/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1180\n",
      "Epoch 39/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1201\n",
      "Epoch 40/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1264\n",
      "Epoch 41/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0985\n",
      "Epoch 42/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1174\n",
      "Epoch 43/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1015\n",
      "Epoch 44/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1125\n",
      "Epoch 45/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1074\n",
      "Epoch 46/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1136\n",
      "Epoch 47/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1138\n",
      "Epoch 48/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1010\n",
      "Epoch 49/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1337\n",
      "Epoch 50/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0844\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1282\n",
      "Epoch 2/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1334\n",
      "Epoch 3/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1705\n",
      "Epoch 4/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1273\n",
      "Epoch 5/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1318\n",
      "Epoch 6/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1405\n",
      "Epoch 7/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1543\n",
      "Epoch 8/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1326\n",
      "Epoch 9/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1435\n",
      "Epoch 10/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1266\n",
      "Epoch 11/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1392\n",
      "Epoch 12/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1224\n",
      "Epoch 13/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1223\n",
      "Epoch 14/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1226\n",
      "Epoch 15/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1271\n",
      "Epoch 16/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1448\n",
      "Epoch 17/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1205\n",
      "Epoch 18/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1355\n",
      "Epoch 19/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1257\n",
      "Epoch 20/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1207\n",
      "Epoch 21/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1265\n",
      "Epoch 22/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1342\n",
      "Epoch 23/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1546\n",
      "Epoch 24/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1140\n",
      "Epoch 25/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1133\n",
      "Epoch 26/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1242\n",
      "Epoch 27/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1262\n",
      "Epoch 28/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1253\n",
      "Epoch 29/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1428\n",
      "Epoch 30/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1075\n",
      "Epoch 31/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1238\n",
      "Epoch 32/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1343\n",
      "Epoch 33/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1253\n",
      "Epoch 34/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1017\n",
      "Epoch 35/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1378\n",
      "Epoch 36/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1142\n",
      "Epoch 37/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1405\n",
      "Epoch 38/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1209\n",
      "Epoch 39/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1080\n",
      "Epoch 40/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1129\n",
      "Epoch 41/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1155\n",
      "Epoch 42/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1179\n",
      "Epoch 43/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1380\n",
      "Epoch 44/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1205\n",
      "Epoch 45/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1067\n",
      "Epoch 46/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1139\n",
      "Epoch 47/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1363\n",
      "Epoch 48/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1033\n",
      "Epoch 49/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1096\n",
      "Epoch 50/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1312\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1144\n",
      "Epoch 2/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1167\n",
      "Epoch 3/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1271\n",
      "Epoch 4/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1083\n",
      "Epoch 5/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1139\n",
      "Epoch 6/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0994\n",
      "Epoch 7/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1222\n",
      "Epoch 8/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1251\n",
      "Epoch 9/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1036\n",
      "Epoch 10/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1531\n",
      "Epoch 11/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1280\n",
      "Epoch 12/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0856\n",
      "Epoch 13/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0954\n",
      "Epoch 14/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1413\n",
      "Epoch 15/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0975\n",
      "Epoch 16/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0951\n",
      "Epoch 17/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1290\n",
      "Epoch 18/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1178\n",
      "Epoch 19/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1526\n",
      "Epoch 20/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1016\n",
      "Epoch 21/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1319\n",
      "Epoch 22/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1278\n",
      "Epoch 23/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1277\n",
      "Epoch 24/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1154\n",
      "Epoch 25/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1139\n",
      "Epoch 26/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1228\n",
      "Epoch 27/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1072\n",
      "Epoch 28/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1238\n",
      "Epoch 29/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1076\n",
      "Epoch 30/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1000\n",
      "Epoch 31/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1142\n",
      "Epoch 32/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1071\n",
      "Epoch 33/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0896\n",
      "Epoch 34/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0958\n",
      "Epoch 35/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1439\n",
      "Epoch 36/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0958\n",
      "Epoch 37/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0873\n",
      "Epoch 38/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1331\n",
      "Epoch 39/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0846\n",
      "Epoch 40/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1317\n",
      "Epoch 41/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1012\n",
      "Epoch 42/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1009\n",
      "Epoch 43/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0989\n",
      "Epoch 44/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1202\n",
      "Epoch 45/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0966\n",
      "Epoch 46/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1111\n",
      "Epoch 47/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.1031\n",
      "Epoch 48/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0884\n",
      "Epoch 49/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1317\n",
      "Epoch 50/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1111\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Epoch 1/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1029\n",
      "Epoch 2/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0814\n",
      "Epoch 3/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0889\n",
      "Epoch 4/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0791\n",
      "Epoch 5/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0736\n",
      "Epoch 6/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0898\n",
      "Epoch 7/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0891\n",
      "Epoch 8/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0783\n",
      "Epoch 9/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0730\n",
      "Epoch 10/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0948\n",
      "Epoch 11/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0761\n",
      "Epoch 12/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0813\n",
      "Epoch 13/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0709\n",
      "Epoch 14/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0733\n",
      "Epoch 15/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0683\n",
      "Epoch 16/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0759\n",
      "Epoch 17/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0665\n",
      "Epoch 18/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0780\n",
      "Epoch 19/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0778\n",
      "Epoch 20/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0757\n",
      "Epoch 21/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0766\n",
      "Epoch 22/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0881\n",
      "Epoch 23/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0797\n",
      "Epoch 24/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0700\n",
      "Epoch 25/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0790\n",
      "Epoch 26/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0693\n",
      "Epoch 27/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0944\n",
      "Epoch 28/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0699\n",
      "Epoch 29/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0641\n",
      "Epoch 30/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0694\n",
      "Epoch 31/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0739\n",
      "Epoch 32/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0654\n",
      "Epoch 33/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0773\n",
      "Epoch 34/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0832\n",
      "Epoch 35/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0781\n",
      "Epoch 36/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0681\n",
      "Epoch 37/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0716\n",
      "Epoch 38/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0764\n",
      "Epoch 39/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0749\n",
      "Epoch 40/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0830\n",
      "Epoch 41/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0712\n",
      "Epoch 42/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0968\n",
      "Epoch 43/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0763\n",
      "Epoch 44/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0868\n",
      "Epoch 45/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0801\n",
      "Epoch 46/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0827\n",
      "Epoch 47/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0739\n",
      "Epoch 48/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0761\n",
      "Epoch 49/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0769\n",
      "Epoch 50/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0592\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Average RMSE: 0.24976668506860733\n",
      "Average MAE: 0.184585589915514\n",
      "Average R2: 0.6563079001576005\n",
      "Average MSE: 0.06389595381915569\n"
     ]
    }
   ],
   "source": [
    "rmse, mae, r2, mse  = 0,0,0,0\n",
    "allhistory= []\n",
    "for X_train, X_test, y_train, y_test in zip(X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm):\n",
    "    X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = map(lambda x: tf.convert_to_tensor(x, dtype=tf.float32), [X_train, y_train, X_test, y_test])\n",
    "    history = model.fit(X_train_tensor, y_train_tensor, epochs=50, batch_size=32)\n",
    "    y_pred = model.predict(X_test_tensor)\n",
    "    y_test_tensor = np.array(y_test_tensor)  # Ensure y_test is a numpy array for consistency\n",
    "    MSE, RMSE, MAE, R2 = DataProcess.evaluate_regression_metrics(y_test_tensor, y_pred)\n",
    "    rmse += RMSE\n",
    "    mae += MAE\n",
    "    r2 += R2\n",
    "    mse += MSE\n",
    "print(f'Average RMSE: {rmse/4}')\n",
    "print(f'Average MAE: {mae/4}')\n",
    "print(f'Average R2: {r2/4}')\n",
    "print(f'Average MSE: {mse/4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e279b7-3740-4292-81e0-d035b596035f",
   "metadata": {},
   "source": [
    " # exploring relationship between seq length and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4265b72c-ebb7-4860-9ec3-72544ce47f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 120)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lstm, X_test_reshape_list, y_train_reshape_list, y_test_reshape_list,_ = preprocess_data_for_tickers(ticker_data_dict, seq_length=30)\n",
    "\n",
    "X_train_lstm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aa6eb87",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Average RMSE: 0.26094838976860046\n",
      "Average MAE: 0.19814933836460114\n",
      "Average R2: 0.6478936985113366\n",
      "Average MSE: 0.06970857176929712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Average RMSE: 0.25480611249804497\n",
      "Average MAE: 0.19268176332116127\n",
      "Average R2: 0.6661315585084718\n",
      "Average MSE: 0.06665468402206898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Average RMSE: 0.26750361174345016\n",
      "Average MAE: 0.2035694569349289\n",
      "Average R2: 0.6402107148619568\n",
      "Average MSE: 0.07368204928934574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Average RMSE: 0.2596155069768429\n",
      "Average MAE: 0.19932741671800613\n",
      "Average R2: 0.6487399728294797\n",
      "Average MSE: 0.06920926459133625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Average RMSE: 0.25618766620755196\n",
      "Average MAE: 0.19194085896015167\n",
      "Average R2: 0.6494851754822031\n",
      "Average MSE: 0.06709161400794983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Average RMSE: 0.2670501060783863\n",
      "Average MAE: 0.20048556104302406\n",
      "Average R2: 0.6233170024255275\n",
      "Average MSE: 0.0732310963794589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Average RMSE: 0.2606876529753208\n",
      "Average MAE: 0.19830460473895073\n",
      "Average R2: 0.6418532920420498\n",
      "Average MSE: 0.0699911406263709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Average RMSE: 0.26020920649170876\n",
      "Average MAE: 0.1965051367878914\n",
      "Average R2: 0.6368189330125069\n",
      "Average MSE: 0.06941829435527325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Average RMSE: 0.25800200924277306\n",
      "Average MAE: 0.19572392478585243\n",
      "Average R2: 0.6407905532401943\n",
      "Average MSE: 0.06809817161411047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Average RMSE: 0.2877213582396507\n",
      "Average MAE: 0.2165694609284401\n",
      "Average R2: 0.5741141071643303\n",
      "Average MSE: 0.08671737462282181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Average RMSE: 0.30594879016280174\n",
      "Average MAE: 0.236997801810503\n",
      "Average R2: 0.5280149713705837\n",
      "Average MSE: 0.09949904587119818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Average RMSE: 0.27679987996816635\n",
      "Average MAE: 0.20830336585640907\n",
      "Average R2: 0.6048954737555384\n",
      "Average MSE: 0.07984141074120998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Average RMSE: 0.2737043499946594\n",
      "Average MAE: 0.20825237408280373\n",
      "Average R2: 0.5953963900377353\n",
      "Average MSE: 0.07703151274472475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Average RMSE: 0.2693989798426628\n",
      "Average MAE: 0.2043554037809372\n",
      "Average R2: 0.6115082593609595\n",
      "Average MSE: 0.07476150803267956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Average RMSE: 0.27610909193754196\n",
      "Average MAE: 0.21002605184912682\n",
      "Average R2: 0.5986590637892166\n",
      "Average MSE: 0.07915975712239742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Average RMSE: 0.26398836076259613\n",
      "Average MAE: 0.1989295408129692\n",
      "Average R2: 0.6255529372345067\n",
      "Average MSE: 0.07153554912656546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Average RMSE: 0.2688494026660919\n",
      "Average MAE: 0.20406921580433846\n",
      "Average R2: 0.6158565401498269\n",
      "Average MSE: 0.07453355379402637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed\\miniconda3\\envs\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Average RMSE: 0.2768929451704025\n",
      "Average MAE: 0.2107882834970951\n",
      "Average R2: 0.5924282212578275\n",
      "Average MSE: 0.07916938606649637\n"
     ]
    }
   ],
   "source": [
    "rmse, mae, r2, mse  = 0,0,0,0\n",
    "allhistory= []\n",
    "for seq_length in range(10,100,5):\n",
    "    X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm , lstm_shape = preprocess_data_for_tickers(ticker_data_dict, seq_length,reshape = False)\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.LSTM(4, return_sequences=True, input_shape=(X_train_lstm[0].shape[1], X_train_lstm[0].shape[2])),\n",
    "        keras.layers.LSTM(4),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    rmse, mae, r2, mse  = 0,0,0,0\n",
    "    for X_train, X_test, y_train, y_test in zip(X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm):\n",
    "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = map(lambda x: tf.convert_to_tensor(x, dtype=tf.float32), [X_train, y_train, X_test, y_test])\n",
    "        history = model.fit(X_train_tensor, y_train_tensor, epochs=50, batch_size=32,verbose = 0)\n",
    "        y_pred = model.predict(X_test_tensor)\n",
    "        y_test_tensor = np.array(y_test_tensor)  # Ensure y_test is a numpy array for consistency\n",
    "        MSE, RMSE, MAE, R2 = DataProcess.evaluate_regression_metrics(y_test_tensor, y_pred)\n",
    "        rmse += RMSE\n",
    "        mae += MAE\n",
    "        r2 += R2\n",
    "        mse += MSE\n",
    "    print(f'Average RMSE: {rmse/4}')\n",
    "    print(f'Average MAE: {mae/4}')\n",
    "    print(f'Average R2: {r2/4}')\n",
    "    print(f'Average MSE: {mse/4}')\n",
    "\n",
    "    #record seq length and loss\n",
    "    allhistory.append([seq_length,rmse/4,mae/4,r2/4,mse/4,history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1b37031-1ff4-4619-84b2-3fb7c8ab2c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'loss vs Seq Length')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting loss vs seq length\n",
    "#plotting rmse,mae,r2,mse vs seq length\n",
    "\n",
    "\n",
    "allhistory = np.array(allhistory)\n",
    "plt.plot(allhistory[:,0],allhistory[:,3])\n",
    "plt.plot(allhistory[:,0],allhistory[:,1])\n",
    "plt.plot(allhistory[:,0],allhistory[:,2])\n",
    "plt.plot(allhistory[:,0],allhistory[:,4])\n",
    "plt.title('loss vs Seq Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa450c4e-296b-4d2e-8131-ac1dd6b77d3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(allhistory[:,\u001b[38;5;241m0\u001b[39m],allhistory[:,\u001b[38;5;241m4\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(allhistory[:,0],allhistory[:,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa44659-15b9-4a3c-805c-ac9aa83d5589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
