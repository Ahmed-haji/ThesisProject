# -*- coding: utf-8 -*-
"""lstmModelSpy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ynkvS87u-jOP0oHE_3qj8NdM4DtU_yHV
"""

import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow import keras
from keras import layers
from sklearn import preprocessing
from sklearn.model_selection import TimeSeriesSplit

aaplHistIV = pd.read_pickle('/content/aapl_mean_iv_2017_2022.pkl')
googHistIV = pd.read_pickle('/content/goog_mean_iv_2017_2022.pkl')
msftHistIV = pd.read_pickle('/content/msft_mean_iv_2017_2022.pkl')
ndxHistIV = pd.read_pickle('/content/ndx_mean_iv_2017_2022.pkl')
spyHistIV = pd.read_pickle('/content/spc_mean_iv_2017_2022.pkl')

def create_sequences(data, seq_length):
    xs, ys = [], []
    for i in range(len(data) - seq_length - 3):
        x = data[i:(i + seq_length)]
        y = data[(i + seq_length), 0]  # Next 3-day IV
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

# # Plotting the training and validation loss
# plt.figure(figsize=(10, 5))
# plt.plot(history.history['loss'], label='Train Loss')
# plt.plot(history.history['val_loss'], label='Validation Loss')
# plt.title('Model Loss Over Epochs')
# plt.ylabel('Loss')
# plt.xlabel('Epoch')
# plt.legend()
# plt.show()

# test_loss = model.evaluate(X_test, y_test)
# print(f'Test Loss: {test_loss}')

# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
# import numpy as np

# y_pred = model.predict(X_test)
# y_test = np.array(y_test)  # Ensure y_test is a numpy array for consistency

# # Calculate MSE
# mse = mean_squared_error(y_test, y_pred)
# print("Mean Squared Error:", mse)

# # Calculate RMSE
# rmse = np.sqrt(mse)
# print("Root Mean Squared Error:", rmse)

# # Calculate MAE
# mae = mean_absolute_error(y_test, y_pred)
# print("Mean Absolute Error:", mae)

# # Calculate R^2
# r2 = r2_score(y_test, y_pred)
# print("R squared:", r2)

window = 21 # realisedvol window size
seq_length = 60

def create_sequences(data, seq_length):
    xs, ys = [], []
    for i in range(len(data) - seq_length - 3):
        x = data[i:(i + seq_length)]
        y = data[(i + seq_length), 0]  # Next 3-day IV
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

def evaluate_model(x_train, x_test, y_train, y_test,scaled_data):

    model = keras.Sequential([
        layers.GRU(100, input_shape=( seq_length, scaled_data.shape[1]), return_sequences=False),
        layers.Dense(1)
    ])

    model.compile(optimizer='adam', loss='mse')

    history = model.fit(x_train, y_train, epochs=50, batch_size=1, validation_split=0.2);

    test_loss = model.evaluate(x_test, y_test)
    print(f'Test Loss: {test_loss}')

    return history, model


def preprocess_data(data, history_name):
  data = data.rename(columns={'date': 'Date'})
  data = data.set_index('Date')

  # get historic data from yfinance
  History = yf.download(history_name, start='2016-01-01', end='2023-12-31', progress = False);
  History['dailyReturn'] = np.log(History['Adj Close']/History['Adj Close'].shift(1))
  History['21dRealisedVol'] = History['dailyReturn'].rolling(window=window).std() * np.sqrt(252)

  historicIVSeries = data['average_iv']
  #historicVolumeSeries = History['Volume'].rolling(21).mean()['2017':'2021']
  dailyReturnSeries= History['dailyReturn']['2017':'2021']
  dailyRealisedVolSeries = History['21dRealisedVol']['2017':'2021']
  df_combined = pd.concat([historicIVSeries,dailyReturnSeries,dailyRealisedVolSeries], axis=1)

  scaler = preprocessing.StandardScaler().fit(df_combined)
  scaled_data = scaler.transform(df_combined)

  X, y = create_sequences(scaled_data, seq_length)
  tscv = TimeSeriesSplit(n_splits=5)

  for train_index, test_index in tscv.split(X):
      X_train, X_test = X[train_index], X[test_index]
      y_train, y_test = y[train_index], y[test_index]

  return X_train, X_test, y_train, y_test, scaled_data

spyHistIV = pd.read_pickle('/content/spc_mean_iv_2017_2022.pkl')

spyHistory ,spyModel = evaluate_model(*preprocess_data(spyHistIV,'^GSPC'));

appleHistory ,appleModel = evaluate_model(*preprocess_data(aaplHistIV,'AAPL'));

msftHistory ,msftModel = evaluate_model(*preprocess_data(msftHistIV,'MSFT'));

googHistory ,googModel = evaluate_model(*preprocess_data(googHistIV,'GOOG'));

ndxHistory,ndxmodel = evaluate_model(*preprocess_data(ndxHistIV,'NDX'));

